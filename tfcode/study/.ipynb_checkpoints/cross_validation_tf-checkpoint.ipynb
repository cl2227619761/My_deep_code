{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files_labels = np.loadtxt(\"./train.csv\", dtype=str, delimiter=\",\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['./mnist_train/3/mnist_train_37167.png', '3'], ['./mnist_train/4/mnist_train_4346.png', '4'], ['./mnist_train/6/mnist_train_46003.png', '6']]\n"
     ]
    }
   ],
   "source": [
    "print(train_files_labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files, labels = zip(*[(l[0], int(l[1])) for l in train_files_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./mnist_train/3/mnist_train_37167.png', './mnist_train/4/mnist_train_4346.png', './mnist_train/6/mnist_train_46003.png')\n",
      "(3, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "print(files[:3])\n",
    "print(labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./mnist_train/5/mnist_train_50019.png'\n",
      " './mnist_train/1/mnist_train_54675.png'\n",
      " './mnist_train/7/mnist_train_28781.png' ...\n",
      " './mnist_train/7/mnist_train_17533.png'\n",
      " './mnist_train/1/mnist_train_58991.png'\n",
      " './mnist_train/0/mnist_train_28101.png']\n",
      "['./mnist_train/3/mnist_train_37167.png'\n",
      " './mnist_train/4/mnist_train_4346.png'\n",
      " './mnist_train/6/mnist_train_46003.png' ...\n",
      " './mnist_train/2/mnist_train_39739.png'\n",
      " './mnist_train/4/mnist_train_24810.png'\n",
      " './mnist_train/8/mnist_train_29729.png']\n",
      "(32000,)\n",
      "(16000,)\n",
      "------------------------------------------------\n",
      "['./mnist_train/3/mnist_train_37167.png'\n",
      " './mnist_train/4/mnist_train_4346.png'\n",
      " './mnist_train/6/mnist_train_46003.png' ...\n",
      " './mnist_train/7/mnist_train_17533.png'\n",
      " './mnist_train/1/mnist_train_58991.png'\n",
      " './mnist_train/0/mnist_train_28101.png']\n",
      "['./mnist_train/5/mnist_train_50019.png'\n",
      " './mnist_train/1/mnist_train_54675.png'\n",
      " './mnist_train/7/mnist_train_28781.png' ...\n",
      " './mnist_train/0/mnist_train_1625.png'\n",
      " './mnist_train/1/mnist_train_53310.png'\n",
      " './mnist_train/5/mnist_train_13331.png']\n",
      "(32000,)\n",
      "(16000,)\n",
      "------------------------------------------------\n",
      "['./mnist_train/3/mnist_train_37167.png'\n",
      " './mnist_train/4/mnist_train_4346.png'\n",
      " './mnist_train/6/mnist_train_46003.png' ...\n",
      " './mnist_train/0/mnist_train_1625.png'\n",
      " './mnist_train/1/mnist_train_53310.png'\n",
      " './mnist_train/5/mnist_train_13331.png']\n",
      "['./mnist_train/5/mnist_train_39964.png'\n",
      " './mnist_train/6/mnist_train_23905.png'\n",
      " './mnist_train/2/mnist_train_48420.png' ...\n",
      " './mnist_train/7/mnist_train_17533.png'\n",
      " './mnist_train/1/mnist_train_58991.png'\n",
      " './mnist_train/0/mnist_train_28101.png']\n",
      "(32000,)\n",
      "(16000,)\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in KFold(3).split(files):\n",
    "    print(np.array(files)[train_index])\n",
    "    print(np.array(files)[test_index])\n",
    "    print(np.array(files)[train_index].shape)\n",
    "    print(np.array(files)[test_index].shape)\n",
    "    print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从iterator创建数据集，好处是使用交叉验证进行处理数据\n",
    "def make_dataset(x_data, y_data, n_splits):\n",
    "    x_trains = []\n",
    "    y_trains = []\n",
    "    x_tests = []\n",
    "    y_tests = []\n",
    "    for train_index, test_index in KFold(n_splits).split(x_data):\n",
    "        x_train, x_test = np.array(x_data)[train_index], np.array(x_data)[test_index]\n",
    "        y_train, y_test = np.array(y_data)[train_index], np.array(y_data)[test_index]\n",
    "        x_trains.append(x_train)\n",
    "        y_trains.append(y_train)\n",
    "        x_tests.append(x_test)\n",
    "        y_tests.append(y_test)\n",
    "    return np.array(x_trains), np.array(y_trains), np.array(x_tests), np.array(y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = make_dataset(files, labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['./mnist_train/5/mnist_train_50019.png'\n",
      "  './mnist_train/1/mnist_train_54675.png'\n",
      "  './mnist_train/7/mnist_train_28781.png' ...\n",
      "  './mnist_train/7/mnist_train_17533.png'\n",
      "  './mnist_train/1/mnist_train_58991.png'\n",
      "  './mnist_train/0/mnist_train_28101.png']\n",
      " ['./mnist_train/3/mnist_train_37167.png'\n",
      "  './mnist_train/4/mnist_train_4346.png'\n",
      "  './mnist_train/6/mnist_train_46003.png' ...\n",
      "  './mnist_train/7/mnist_train_17533.png'\n",
      "  './mnist_train/1/mnist_train_58991.png'\n",
      "  './mnist_train/0/mnist_train_28101.png']\n",
      " ['./mnist_train/3/mnist_train_37167.png'\n",
      "  './mnist_train/4/mnist_train_4346.png'\n",
      "  './mnist_train/6/mnist_train_46003.png' ...\n",
      "  './mnist_train/0/mnist_train_1625.png'\n",
      "  './mnist_train/1/mnist_train_53310.png'\n",
      "  './mnist_train/5/mnist_train_13331.png']]\n",
      "(3, 32000)\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 1 7 ... 7 1 0]\n",
      " [3 4 6 ... 7 1 0]\n",
      " [3 4 6 ... 0 1 5]]\n",
      "(3, 32000)\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['./mnist_train/5/mnist_train_50019.png', '5'],\n",
       "       ['./mnist_train/1/mnist_train_54675.png', '1'],\n",
       "       ['./mnist_train/7/mnist_train_28781.png', '7'],\n",
       "       ...,\n",
       "       ['./mnist_train/7/mnist_train_17533.png', '7'],\n",
       "       ['./mnist_train/1/mnist_train_58991.png', '1'],\n",
       "       ['./mnist_train/0/mnist_train_28101.png', '0']], dtype='<U37')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack((x_train[0], y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_image(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_png(image_string)\n",
    "    image_reshaped = tf.reshape(image_decoded, [28, 28, 1])\n",
    "    image_converted = tf.cast(image_reshaped, tf.float32)\n",
    "    image_scaled = tf.divide(image_converted, 255.)\n",
    "    labels = tf.cast(label, tf.int32)\n",
    "    return image_scaled, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_1 = tf.data.Dataset.from_tensor_slices((x_train[0], y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorShape([]), TensorShape([]))\n",
      "(tf.string, tf.int64)\n"
     ]
    }
   ],
   "source": [
    "print(train_ds_1.output_shapes)\n",
    "print(train_ds_1.output_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'./mnist_train/5/mnist_train_50019.png', 5)\n"
     ]
    }
   ],
   "source": [
    "iterator = train_ds_1.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(1):\n",
    "        print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorShape([Dimension(28), Dimension(28), Dimension(1)]), TensorShape([]))\n",
      "(tf.float32, tf.int32)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mt\n",
    "\n",
    "train_ds_1 = train_ds_1.map(_parse_image, num_parallel_calls=mt.cpu_count())\n",
    "print(train_ds_1.output_shapes)\n",
    "print(train_ds_1.output_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = train_ds_1.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(1):\n",
    "        tmp_im, tmp_label = sess.run(next_element)\n",
    "        tmp_im = tmp_im.squeeze()\n",
    "        print(tmp_label)\n",
    "        print(\"------------------------------------\")\n",
    "        plt.imshow(tmp_im, cmap=\"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建LeNet-5模型\n",
    "class MyModel:\n",
    "    def __init__(self, data_x, data_y):\n",
    "        self.n_classes = 10\n",
    "        self._create_architecture(data_x, data_y)\n",
    "        \n",
    "    def _create_architecture(self, x, y):\n",
    "        self.logits = self._create_model(x)\n",
    "        predictions = tf.argmax(self.logits, 1, output_type=tf.int32)\n",
    "        self.loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=y, logits=self.logits))\n",
    "        self.train_step = tf.train.AdamOptimizer().minimize(self.loss)\n",
    "        self.accuracy = tf.reduce_sum(tf.cast(tf.equal(predictions, y), tf.float32))\n",
    "        \n",
    "    def _create_model(self, x):\n",
    "        input_tensor = tf.keras.layers.Input(shape=[28, 28, 1], tensor=x, name=\"Input\")\n",
    "        net = tf.keras.layers.Conv2D(kernel_size=(5, 5), filters=20, activation=\"relu\", name=\"Conv1\")(input_tensor)\n",
    "        net = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name=\"Pool1\")(net)\n",
    "        net = tf.keras.layers.Conv2D(kernel_size=(5, 5), filters=50, activation=\"relu\", name=\"Conv2\")(net)\n",
    "        net = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name=\"Pool2\")(net)\n",
    "        net = tf.keras.layers.Flatten(name=\"Flatten\")(net)\n",
    "        net = tf.keras.layers.Dense(120, activation=\"relu\", name=\"relu\")(net)\n",
    "        net = tf.keras.layers.Dense(84, activation=\"relu\", name=\"relu\")(net)\n",
    "        net = tf.keras.layers.Dense(self.n_classes, activation=\"linear\", name=\"Logits\")(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉验证的tensorflow实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######Fold: 1########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [04:11<00:00, 127.48it/s] \n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training accuracy: 0.9009, loss: 0.0032\n",
      "Val accuracy: 0.9686, loss: 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:15<00:00, 2130.09it/s]\n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Training accuracy: 0.9758, loss: 0.0008\n",
      "Val accuracy: 0.9764, loss: 0.0007\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:15<00:00, 2112.53it/s]\n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Training accuracy: 0.9836, loss: 0.0005\n",
      "Val accuracy: 0.9829, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:15<00:00, 2132.87it/s]\n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "Training accuracy: 0.9871, loss: 0.0004\n",
      "Val accuracy: 0.9826, loss: 0.0006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:14<00:00, 2151.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Training accuracy: 0.9895, loss: 0.0003\n",
      "Val accuracy: 0.9856, loss: 0.0005\n",
      "\n",
      "######Fold: 2########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:15<00:00, 2088.15it/s]\n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training accuracy: 0.9056, loss: 0.0032\n",
      "Val accuracy: 0.9659, loss: 0.0011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:15<00:00, 2094.68it/s]\n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Training accuracy: 0.9746, loss: 0.0009\n",
      "Val accuracy: 0.9798, loss: 0.0007\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:15<00:00, 2127.82it/s]\n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Training accuracy: 0.9827, loss: 0.0006\n",
      "Val accuracy: 0.9825, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:14<00:00, 2139.27it/s]\n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "Training accuracy: 0.9864, loss: 0.0004\n",
      "Val accuracy: 0.9862, loss: 0.0004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:14<00:00, 2160.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Training accuracy: 0.9890, loss: 0.0003\n",
      "Val accuracy: 0.9847, loss: 0.0005\n",
      "\n",
      "######Fold: 3########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:15<00:00, 2130.87it/s]\n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training accuracy: 0.9045, loss: 0.0032\n",
      "Val accuracy: 0.9690, loss: 0.0011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:15<00:00, 2127.41it/s]\n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Training accuracy: 0.9754, loss: 0.0008\n",
      "Val accuracy: 0.9762, loss: 0.0008\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:14<00:00, 2135.81it/s]\n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Training accuracy: 0.9832, loss: 0.0005\n",
      "Val accuracy: 0.9834, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:14<00:00, 2144.82it/s]\n",
      "  0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "Training accuracy: 0.9878, loss: 0.0004\n",
      "Val accuracy: 0.9854, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:14<00:00, 2147.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Training accuracy: 0.9893, loss: 0.0003\n",
      "Val accuracy: 0.9867, loss: 0.0005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 实施交叉验证\n",
    "for i in range(len(x_train)):\n",
    "    print(\"######Fold: {}########\".format(i + 1))\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train[i], y_train[i]))\n",
    "    train_ds = train_ds.map(_parse_image, num_parallel_calls=mt.cpu_count())\n",
    "    train_ds = train_ds.shuffle(32000).batch(100)\n",
    "    \n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((x_test[i], y_test[i]))\n",
    "    val_ds = val_ds.map(_parse_image, num_parallel_calls=mt.cpu_count())\n",
    "    val_ds = val_ds.batch(100)\n",
    "    \n",
    "    # 创建句柄\n",
    "    handle = tf.placeholder(tf.string, shape=[])\n",
    "    iterator = tf.data.Iterator.from_string_handle(handle, train_ds.output_types, train_ds.output_shapes)\n",
    "    data_x, data_y = iterator.get_next()\n",
    "    model = MyModel(data_x, data_y)\n",
    "    \n",
    "    # 可重新初始化迭代器\n",
    "    train_val_iterator = tf.data.Iterator.from_structure(train_ds.output_types, train_ds.output_shapes)\n",
    "    train_iterator = train_val_iterator.make_initializer(train_ds)\n",
    "    val_iterator = train_val_iterator.make_initializer(val_ds)\n",
    "    \n",
    "    # 创建会话\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        train_val_string = sess.run(train_val_iterator.string_handle())\n",
    "        \n",
    "        for epoch in range(5):\n",
    "            train_loss, train_acc = 0, 0\n",
    "            val_loss, val_acc = 0, 0\n",
    "            \n",
    "            # 开始训练\n",
    "            sess.run(train_iterator)\n",
    "            try:\n",
    "                with tqdm(total=32000) as pbar:\n",
    "                    while True:\n",
    "                        _, loss, acc = sess.run([model.train_step, model.loss, model.accuracy], feed_dict={handle: train_val_string})\n",
    "                        train_loss += loss\n",
    "                        train_acc += acc\n",
    "                        pbar.update(100)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            \n",
    "            # 开始验证\n",
    "            sess.run(val_iterator)\n",
    "            try:\n",
    "                while True:\n",
    "                    loss, acc = sess.run([model.loss, model.accuracy], feed_dict={handle: train_val_string})\n",
    "                    val_loss += loss\n",
    "                    val_acc += acc\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            \n",
    "            print(\"Epoch: {}\".format(epoch + 1))\n",
    "            print(\"Training accuracy: {:.4f}, loss: {:.4f}\".format(train_acc / 32000, train_loss / 32000))\n",
    "            print(\"Val accuracy: {:.4f}, loss: {:.4f}\\n\".format(val_acc / 16000, val_loss / 16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
