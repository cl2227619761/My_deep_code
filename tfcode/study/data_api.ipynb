{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在TensorFlow中使用Dataset和Iterator的教程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset的创建\n",
    "可以从numpy数组，TFRecords，TXT file，CSV file进行创建，最常见的是通过numpy或者tensor创建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from_tensor_slices\n",
    "这种方法可以接受一个或者多个numpy或者tensor对象，注意传进多个对象时，数组的第零个维度应该一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.range(10, 15))\n",
    "# 向外弹出数据的时候，一次弹出一个元素，即10，11，12， 13， 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices((tf.range(30, 45, 3), np.arange(60, 70, 2)))\n",
    "# 向外弹出数据的时候，一次弹出一个元组，即(30, 60), (33, 62), (36, 64), (39, 66), (42, 68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60, 62, 64, 66, 68])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(60, 70, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(np.arange(60, 70, 2).shape[0])\n",
    "print(tf.range(30, 45, 3).shape[0])\n",
    "# 传进多个数组的时候，每个数组的第零个维度是一致的，其实第零个维度就是样本量维度，当然要一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorShape([]), TensorShape([]))\n",
      "(tf.int32, tf.int64)\n"
     ]
    }
   ],
   "source": [
    "print(dataset2.output_shapes)\n",
    "# dataset.output_shapes打印的shape是省略第零个维度的\n",
    "print(dataset2.output_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions 10 and 5 are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-126e43f065cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 第零个维度不一致的时候会出错\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m       \u001b[0mbatch_dim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize_many_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m       raise ValueError(\"Dimensions %s and %s are not compatible\" % (self,\n\u001b[0;32m--> 116\u001b[0;31m                                                                     other))\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions 10 and 5 are not compatible"
     ]
    }
   ],
   "source": [
    "# 第零个维度不一致的时候会出错\n",
    "dataset3 = tf.data.Dataset.from_tensor_slices((tf.range(10), np.arange(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from_tensors\n",
    "这个方法也可以接受一个或者多个数组，但是和from_tensor_slices的不同是：不支持batch，一次会弹出所有的元素；多个数组的第零个维度可以不一致。适合小数据集或者一次使用全部数据的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 11 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensors(tf.range(10, 15))\n",
    "# 一次弹出所有数据，形如[10, 11, 12, 13, 14]\n",
    "iterator1 = dataset1.make_one_shot_iterator()\n",
    "next_element = iterator1.get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([30, 33, 36, 39, 42], dtype=int32), array([60, 62, 64, 66, 68]))\n"
     ]
    }
   ],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensors((tf.range(30, 45, 3), np.arange(60, 70, 2)))\n",
    "# 一次弹出全部元素，形如([30, 33, 36, 39, 42], [60, 62, 64, 66, 68])\n",
    "iterator2 = dataset2.make_one_shot_iterator()\n",
    "next_element = iterator2.get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32), array([0, 1, 2, 3, 4]))\n"
     ]
    }
   ],
   "source": [
    "dataset3 = tf.data.Dataset.from_tensors((tf.range(10), np.arange(5)))\n",
    "# from_tensors支持第零维度不一致\n",
    "iterator3 = dataset3.make_one_shot_iterator()\n",
    "next_element = iterator3.get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from_generator\n",
    "这种方法接受的是生成器函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(sequence_type):\n",
    "    if sequence_type == 1:\n",
    "        for i in range(5):\n",
    "            yield 10 + i\n",
    "    elif sequence_type == 2:\n",
    "        for i in range(5):\n",
    "            yield (30 + 3 * i, 60 + 2 * i)\n",
    "    elif sequence_type == 3:\n",
    "        for i in range(1, 4):\n",
    "            yield (i, [\"Hi\"] * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unknown>\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_generator(generator, (tf.int32), args=([1]))\n",
    "print(dataset1.output_shapes)\n",
    "print(dataset1.output_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "iterator1 = dataset1.make_initializable_iterator()\n",
    "next_element = iterator1.get_next()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator1.initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_element))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tf.int32, tf.int32)\n",
      "(TensorShape(None), TensorShape(None))\n"
     ]
    }
   ],
   "source": [
    "dataset2 = tf.data.Dataset.from_generator(generator, (tf.int32, tf.int32), args=([2]))\n",
    "print(dataset2.output_types)\n",
    "print(dataset2.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 60)\n",
      "(33, 62)\n",
      "(36, 64)\n",
      "(39, 66)\n",
      "(42, 68)\n"
     ]
    }
   ],
   "source": [
    "iterator2 = dataset2.make_one_shot_iterator()\n",
    "next_element = iterator2.get_next()\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_element))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorShape(None), TensorShape(None))\n",
      "(tf.int32, tf.string)\n"
     ]
    }
   ],
   "source": [
    "dataset3 = tf.data.Dataset.from_generator(generator, (tf.int32, tf.string), args=([3]))\n",
    "print(dataset3.output_shapes)\n",
    "print(dataset3.output_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, array([b'Hi'], dtype=object))\n",
      "(2, array([b'Hi', b'Hi'], dtype=object))\n",
      "(3, array([b'Hi', b'Hi', b'Hi'], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "iterator3 = dataset3.make_one_shot_iterator()\n",
    "next_element = iterator3.get_next()\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_element))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset的变换操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch\n",
    "batch操作会将dataset中的元素顺序的进行划分批次的操作\n",
    "\n",
    "![batch](./batch.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat\n",
    "repeat操作会对dataset中的元素进行复制操作\n",
    "\n",
    "![repeat](./repeat.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shuffle](./shuffle.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle的buffer_size参数是一次加载进缓存器多少个元素的意思，弹出一个补一个；抽样是从缓存器往外抽"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shuffle1](./shuffle1.jpg)\n",
    "\n",
    "![shuffle2](./shuffle2.jpg)\n",
    "\n",
    "![shuffle3](./shuffle3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例子1\n",
    "filenames = [\"filename_01.jpg\", \"filename_02.jpg\", \"filename_03.jpg\", \"filename_04.jpg\", \"filename_05.jpg\",\n",
    "            \"filename_11.jpg\", \"filename_12.jpg\", \"filename_13.jpg\", \"filename_14.jpg\", \"filename_15.jpg\"]\n",
    "labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'filename_02.jpg', 0)\n",
      "(b'filename_04.jpg', 0)\n",
      "(b'filename_03.jpg', 0)\n",
      "(b'filename_12.jpg', 1)\n",
      "(b'filename_01.jpg', 0)\n",
      "(b'filename_14.jpg', 1)\n",
      "(b'filename_05.jpg', 0)\n",
      "(b'filename_15.jpg', 1)\n",
      "(b'filename_13.jpg', 1)\n",
      "(b'filename_11.jpg', 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "dataset = dataset.shuffle(buffer_size=5)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原理\n",
    "\n",
    "[01, 02, 03, 04, 05] --> 02\n",
    "\n",
    "[01, 11, 03, 04, 05] --> 04\n",
    "\n",
    "[01, 11, 03, 12, 05] --> 03\n",
    "\n",
    "[01, 11, 13, 12, 05] --> 12\n",
    "\n",
    "[01, 11, 13, 14, 05] --> 01\n",
    "\n",
    "[15, 11, 13, 14, 05] --> 14\n",
    "\n",
    "[15, 11, 13, 05] --> 05\n",
    "\n",
    "[15, 11, 13] --> 15\n",
    "\n",
    "[11, 13] --> 13\n",
    "\n",
    "[11] --> 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "# 例子2\n",
    "cat = np.repeat(0, repeats=100)\n",
    "dog = np.repeat(1, repeats=100)\n",
    "labels = np.concatenate([cat, dog])\n",
    "print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "dataset = dataset.shuffle(buffer_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for _ in range(200):\n",
    "        print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'filename_12.jpg', 1)\n",
      "(b'filename_04.jpg', 0)\n",
      "(b'filename_03.jpg', 0)\n",
      "(b'filename_11.jpg', 1)\n",
      "(b'filename_05.jpg', 0)\n",
      "(b'filename_14.jpg', 1)\n",
      "(b'filename_01.jpg', 0)\n",
      "(b'filename_13.jpg', 1)\n",
      "(b'filename_15.jpg', 1)\n",
      "(b'filename_02.jpg', 0)\n"
     ]
    }
   ],
   "source": [
    "# 例子3：最好设置buffer_size=len(files)\n",
    "filenames = [\"filename_01.jpg\", \"filename_02.jpg\", \"filename_03.jpg\", \"filename_04.jpg\", \"filename_05.jpg\",\n",
    "            \"filename_11.jpg\", \"filename_12.jpg\", \"filename_13.jpg\", \"filename_14.jpg\", \"filename_15.jpg\"]\n",
    "labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "dataset = dataset.shuffle(buffer_size=10)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat'\n",
      " 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat'\n",
      " 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat'\n",
      " 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat'\n",
      " 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat'\n",
      " 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat'\n",
      " 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat'\n",
      " 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat' 'cat'\n",
      " 'cat' 'cat' 'cat' 'cat' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog'\n",
      " 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog'\n",
      " 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog'\n",
      " 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog'\n",
      " 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog'\n",
      " 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog'\n",
      " 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog'\n",
      " 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog'\n",
      " 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog' 'dog']\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "# 例子4：结合batch进行抽取，观看buffer_size的大小变化产生的影响\n",
    "cats = np.repeat(\"cat\", repeats=100)\n",
    "dogs = np.repeat(\"dog\", repeats=100)\n",
    "labels = np.concatenate([cats, dogs])\n",
    "print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "dataset = dataset.shuffle(buffer_size=10)\n",
    "dataset = dataset.batch(20)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat'\n",
      " b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat']\n",
      "[b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat'\n",
      " b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat']\n",
      "[b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat'\n",
      " b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat']\n",
      "[b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat'\n",
      " b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat']\n",
      "[b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat' b'cat'\n",
      " b'cat' b'cat' b'cat' b'dog' b'cat' b'cat' b'cat' b'dog' b'cat' b'cat']\n",
      "[b'cat' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog'\n",
      " b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'cat' b'dog']\n",
      "[b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog'\n",
      " b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog']\n",
      "[b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog'\n",
      " b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog']\n",
      "[b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog'\n",
      " b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog']\n",
      "[b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog'\n",
      " b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog' b'dog']\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_element))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上面的结果可以看出来，当buffer_size很小的时候，显然不合适"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat' 'cat' 'cat' ... 'dog' 'dog' 'dog']\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# 例子4\n",
    "cats = np.repeat(\"cat\", repeats=5000)\n",
    "dogs = np.repeat(\"dog\", repeats=5000)\n",
    "labels = np.concatenate([cats, dogs])\n",
    "print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "num_epochs = np.ceil(len(labels) / batch_size).astype(np.int32)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改buffer_size大小为len(files)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "dataset = dataset.shuffle(buffer_size=len(labels))\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "batch_res = []\n",
    "with tf.Session() as sess:\n",
    "    for i in range(num_epochs):\n",
    "        tmp = sess.run(next_element)\n",
    "        batch_res.append(tmp)\n",
    "print(len(batch_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49']\n"
     ]
    }
   ],
   "source": [
    "label_list = [str(i) for i in range(int(num_epochs))]\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106, 95, 103, 95, 97, 89, 105, 89, 97, 103, 101, 100, 91, 97, 106, 98, 114, 102, 91, 109, 94, 93, 96, 98, 109, 114, 105, 99, 103, 96, 103, 91, 93, 107, 103, 101, 100, 103, 101, 107, 110, 95, 102, 96, 96, 87, 99, 103, 98, 110]\n"
     ]
    }
   ],
   "source": [
    "num_list_cat = [batch_res[i].tolist().count(b\"cat\") for i in range(int(num_epochs))]\n",
    "print(num_list_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94, 105, 97, 105, 103, 111, 95, 111, 103, 97, 99, 100, 109, 103, 94, 102, 86, 98, 109, 91, 106, 107, 104, 102, 91, 86, 95, 101, 97, 104, 97, 109, 107, 93, 97, 99, 100, 97, 99, 93, 90, 105, 98, 104, 104, 113, 101, 97, 102, 90]\n"
     ]
    }
   ],
   "source": [
    "num_list_dog = [batch_res[i].tolist().count(b\"dog\") for i in range(num_epochs)]\n",
    "print(num_list_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(num_list_cat))\n",
    "print(x)\n",
    "plt.figure(figsize=(15, 7))\n",
    "\"\"\"\n",
    "绘制条形图\n",
    "left:长条形中点横坐标\n",
    "height:长条形高度\n",
    "width:长条形宽度，默认值0.8\n",
    "label:为后面设置legend准备\n",
    "\"\"\"\n",
    "cat_ = plt.bar(x, height=num_list_cat, width=0.4, alpha=0.8, label=\"cat\")\n",
    "dog_ = plt.bar([i + 0.4 for i in x], height=num_list_dog, width=0.4, label=\"dog\")\n",
    "plt.ylim(0, 130)     # y轴取值范围\n",
    "plt.ylabel(\"num\")\n",
    "\"\"\"\n",
    "设置x轴刻度显示值\n",
    "参数一：中点坐标\n",
    "参数二：显示值\n",
    "\"\"\"\n",
    "plt.xticks([index + 0.2 for index in x], label_list)\n",
    "plt.xlabel(\"batch\")\n",
    "plt.title(\"buffer_size=len(files)\")\n",
    "plt.legend()     # 设置题注\n",
    "# 编辑文本\n",
    "# for rect in cat_:\n",
    "#     height = rect.get_height()\n",
    "#     plt.text(rect.get_x() + rect.get_width() / 2, height+1, str(height), ha=\"center\", va=\"bottom\")\n",
    "# for rect in dog_:\n",
    "#     height = rect.get_height()\n",
    "#     plt.text(rect.get_x() + rect.get_width() / 2, height+1, str(height), ha=\"center\", va=\"bottom\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat' 'cat' 'cat' ... 'dog' 'dog' 'dog']\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# 例子5：将buffer_size改小的结果\n",
    "cats = np.repeat(\"cat\", repeats=5000)\n",
    "dogs = np.repeat(\"dog\", repeats=5000)\n",
    "labels = np.concatenate([cats, dogs])\n",
    "print(labels)\n",
    "print(labels.shape)\n",
    "\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(labels)\n",
    "dataset2 = dataset2.shuffle(buffer_size=20)\n",
    "dataset2 = dataset2.batch(batch_size)\n",
    "\n",
    "iterator2 = dataset2.make_one_shot_iterator()\n",
    "next_element2 = iterator2.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "num_epochs = np.ceil(len(labels) / batch_size).astype(np.int32)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "batch_res2 = []\n",
    "with tf.Session() as sess:\n",
    "    for i in range(num_epochs):\n",
    "        tmp = sess.run(next_element2)\n",
    "        batch_res2.append(tmp)\n",
    "print(len(batch_res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49']\n"
     ]
    }
   ],
   "source": [
    "label_list2 = [str(i) for i in range(int(num_epochs))]\n",
    "print(label_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 195, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "num_list_cat2 = [batch_res2[i].tolist().count(b\"cat\") for i in range(int(num_epochs))]\n",
    "print(num_list_cat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 195, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]\n"
     ]
    }
   ],
   "source": [
    "num_list_dog2 = [batch_res2[i].tolist().count(b\"dog\") for i in range(num_epochs)]\n",
    "print(num_list_dog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x2 = np.arange(len(num_list_cat2))\n",
    "print(x)\n",
    "plt.figure(figsize=(15, 7))\n",
    "\"\"\"\n",
    "绘制条形图\n",
    "left:长条形中点横坐标\n",
    "height:长条形高度\n",
    "width:长条形宽度，默认值0.8\n",
    "label:为后面设置legend准备\n",
    "\"\"\"\n",
    "cat2_ = plt.bar(x2, height=num_list_cat2, width=0.4, alpha=0.8, label=\"cat\")\n",
    "dog2_ = plt.bar([i + 0.4 for i in x2], height=num_list_dog2, width=0.4, label=\"dog\")\n",
    "plt.ylim(0, 230)     # y轴取值范围\n",
    "plt.ylabel(\"num\")\n",
    "\"\"\"\n",
    "设置x轴刻度显示值\n",
    "参数一：中点坐标\n",
    "参数二：显示值\n",
    "\"\"\"\n",
    "plt.xticks([index + 0.2 for index in x2], label_list2)\n",
    "plt.xlabel(\"batch\")\n",
    "plt.title(\"buffer_size << len(files)\")\n",
    "plt.legend()     # 设置题注\n",
    "# 编辑文本\n",
    "# for rect in cat_:\n",
    "#     height = rect.get_height()\n",
    "#     plt.text(rect.get_x() + rect.get_width() / 2, height+1, str(height), ha=\"center\", va=\"bottom\")\n",
    "# for rect in dog_:\n",
    "#     height = rect.get_height()\n",
    "#     plt.text(rect.get_x() + rect.get_width() / 2, height+1, str(height), ha=\"center\", va=\"bottom\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shuffle的buffer_size小结：\n",
    "1. buffer_size的设置要根据实际情况而定，最好是大于等于文件名数量的总数\n",
    "2. 当buffer_size设小的时候，就会出现某些batch全是一类相同的标签，对训练不利"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map\n",
    "该方法能够对dataset数据集中的每一个元素进行操作。比如进行一些数据增强的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Map](./map.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_element), end=\" \")\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter\n",
    "在训练的过程中，如果想把某些元素从dataset中过滤掉，可以使用filter方法\n",
    "\n",
    "![Filter](./filter.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "input_array = np.arange(8)\n",
    "print(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_only_even(x):\n",
    "    return tf.reshape(tf.equal(x % 2, 0), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(pass_only_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 4 6 "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_element), end=\" \")\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一个综合的例子\n",
    "综合使用shuffle, repeat, batch的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "# 将创建一个内容为[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]的dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.repeat(2)\n",
    "# 将产生一个内容为[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]的dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(buffer_size=20)\n",
    "# 将对dataset进行shuffle操作，缓存器的大小为样本数大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: x * 3)\n",
    "# 将dataset中的每个元素乘以3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fn(x):\n",
    "    # 将除以5余数为1的元素剔除\n",
    "    return tf.reshape(tf.not_equal(x % 5, 1), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(filter_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(batch_size=4)\n",
    "# batch_size的大小为4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24  3 15 12] [ 3 12 15 27] [24  9 27  0] [ 9  0 18 18] "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_element), end=\" \")\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转换处理的顺序对数据的影响\n",
    "对数据进行转换的顺序是很重要的。对于同样的数据，如果处理的顺序不一样，那么训练出来的模型也会不一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一种处理顺序\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "# [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "dataset1 = dataset1.batch(4)\n",
    "# [0, 1, 2, 3], [4, 5, 6, 7], [8, 9]\n",
    "dataset1 = dataset1.repeat(2)\n",
    "# [0, 1, 2, 3], [4, 5, 6, 7], [8, 9], [0, 1, 2, 3], [4, 5, 6, 7], [8, 9]\n",
    "dataset1 = dataset1.shuffle(6)  # 在batch水平上进行shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset1.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 9] [4 5 6 7] [4 5 6 7] [0 1 2 3] [0 1 2 3] [8 9] "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_element), end=\" \")\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二种处理顺序\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "# [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "dataset2 = dataset2.shuffle(10)\n",
    "dataset2 = dataset2.repeat(2)\n",
    "dataset2 = dataset2.batch(4)\n",
    "\n",
    "iterator = dataset2.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 9 2 0] [1 5 8 4] [6 7 6 5] [9 7 0 8] [1 3 4 2] "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(next_element), end=\" \")\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个例子：模型搭建，数据输入。一套下来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建LeNet-5模型\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, data_x, data_y):\n",
    "        self.n_class = 10\n",
    "        self._create_architecture(data_x, data_y)\n",
    "        self.input_data = None\n",
    "        self.logits = None\n",
    "        \n",
    "    def _create_architecture(self, data_x, data_y):\n",
    "        y_hot = tf.one_hot(data_y, self.n_class)\n",
    "        with tf.name_scope(\"logits\"):\n",
    "            logits = self._create_model(data_x)\n",
    "        with tf.name_scope(\"predictions\"):\n",
    "            predictions = tf.argmax(logits, 1, output_type=tf.int32)\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            self.loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=y_hot, logits=logits))\n",
    "        with tf.name_scope(\"train\"):\n",
    "            self.optimizer = tf.train.AdamOptimizer().minimize(self.loss)\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            self.accuracy = tf.reduce_sum(tf.cast(tf.equal(predictions, data_y), tf.float32))\n",
    "    def _create_model(self, x):\n",
    "        input_data = tf.keras.layers.Input(shape=[28, 28, 1], name=\"Input\", tensor=x)\n",
    "        x = tf.keras.layers.Conv2D(kernel_size=(5, 5), filters=20, activation=\"relu\", name=\"Conv1\")(input_data)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding=\"same\", name=\"Pool1\")(x)\n",
    "        x = tf.keras.layers.Conv2D(kernel_size=(5, 5), filters=50, activation=\"relu\", name=(\"Conv2\"))(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding=\"same\", name=\"Pool2\")(x)\n",
    "        x = tf.keras.layers.Flatten(name=\"Flatten\")(x)\n",
    "        x = tf.keras.layers.Dense(120, activation='relu', name=\"Dense1\")(x)\n",
    "        x = tf.keras.layers.Dense(84, activation=\"relu\", name=\"Dense2\")(x)\n",
    "        x = tf.keras.layers.Dense(self.n_class, activation=\"linear\", name=\"logits\")(x)\n",
    "        return x\n",
    "    \n",
    "    def _model_summary(self):\n",
    "        self.input_data = tf.keras.layers.Input(shape=[28, 28, 1], name=\"Input\")\n",
    "        self.logits = self._create_model(self.input_data)\n",
    "        model_structure = tf.keras.models.Model(inputs=self.input_data, outputs=self.logits)\n",
    "        model_structure.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./train_tfrecords/train.tfrecord-045', './train_tfrecords/train.tfrecord-002', './train_tfrecords/train.tfrecord-033']\n",
      "-------------------------\n",
      "['./test_tfrecords/test.tfrecord-003', './test_tfrecords/test.tfrecord-001', './test_tfrecords/test.tfrecord-002']\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集dataset\n",
    "import os\n",
    "\n",
    "train_filenames = [os.path.join(\"./train_tfrecords/\", i) for i in os.listdir(\"./train_tfrecords/\")]\n",
    "val_filenames = [os.path.join(\"./test_tfrecords/\", i) for i in os.listdir(\"./test_tfrecords/\")]\n",
    "print(train_filenames[:3])\n",
    "print(\"-------------------------\")\n",
    "print(val_filenames[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(record):\n",
    "    keys_to_features = {\"img_raw\": tf.FixedLenFeature((), tf.string, default_value=\"\"), \"label\": tf.FixedLenFeature((), tf.int64, default_value=tf.zeros([], tf.int64))}\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "    images = tf.decode_raw(parsed[\"img_raw\"], tf.uint8)\n",
    "    images = tf.reshape(images, [28, 28, 1])\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    images = tf.divide(images, 255.)\n",
    "    labels = tf.cast(parsed[\"label\"], tf.int32)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迭代器iterator\n",
    "接下来，需要构建迭代器。TensorFlow提供了四种迭代器，每一种迭代器都有自己的用途和特定目的。下面是一般的迭代器构建流程：\n",
    "\n",
    "```python\n",
    "# 首先创建dataset并进行转换操作\n",
    "dataset = << Create Dataset object >>\n",
    "dataset = << Perform transformations on dataset >>\n",
    "\n",
    "# 创建迭代器\n",
    "iterator = << Create iterator using dataset >>\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# 创建session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            sess.run(next_batch)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-shot iterator\n",
    "这是最基础的迭代器。要求必须在生成迭代器之前对数据集dataset中的元素进行转换操作，它会遍历迭代器中的所有元素直到穷尽，然后这个迭代器就不能再使用了。它的缺点是占用很大的内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用one-shot iterator训练的例子\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(train_filenames)\n",
    "train_ds = train_ds.map(_parse_function)\n",
    "train_ds = train_ds.shuffle(60000).repeat(epochs).batch(batch_size)\n",
    "iterator = train_ds.make_one_shot_iterator()\n",
    "\n",
    "data_x, data_y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 24, 24, 20)        520       \n",
      "_________________________________________________________________\n",
      "Pool1 (MaxPooling2D)         (None, 12, 12, 20)        0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 8, 8, 50)          25050     \n",
      "_________________________________________________________________\n",
      "Pool2 (MaxPooling2D)         (None, 4, 4, 50)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 120)               96120     \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 132,704\n",
      "Trainable params: 132,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model._model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 60000 * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600000/600000 [04:25<00:00, 2255.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average training accuracy: 0.9887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess, tqdm(total=iterations) as pbar:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    total_acc = 0\n",
    "    try:\n",
    "        while True:\n",
    "            acc, _ = sess.run([model.accuracy, model.optimizer])\n",
    "            total_acc += acc\n",
    "            pbar.update(batch_size)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "print(\"\\nAverage training accuracy: {:.4f}\".format(total_acc / iterations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initializable\n",
    "one-shot iterator的缺点是会在内存中重复同一个训练dataset，并且无法对验证集进行验证。而initializable iterator则克服了这些缺点，在运行之前需要对该迭代器进行初始化。\n",
    "\n",
    "而initializable迭代器的缺点是，训练集和验证集使用的是同一个迭代器管道"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinitializable迭代器\n",
    "优点是训练集和验证集可以走不同的管道进行输入，需要注意的是不同的dataset的数据类型要一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(1)]), TensorShape([Dimension(None)])) (tf.float32, tf.int32)\n"
     ]
    }
   ],
   "source": [
    "# 使用reinitializable迭代器进行训练和验证的例子\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# 创建用于训练和验证的dataset\n",
    "train_dataset = tf.data.TFRecordDataset(train_filenames)\n",
    "train_dataset = train_dataset.map(_parse_function).shuffle(60000).batch(batch_size)\n",
    "val_dataset = tf.data.TFRecordDataset(val_filenames)\n",
    "val_dataset = val_dataset.map(_parse_function).batch(batch_size)\n",
    "print(train_dataset.output_shapes, train_dataset.output_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建迭代器\n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "data_x, data_y = iterator.get_next()\n",
    "model = Model(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 24, 24, 20)        520       \n",
      "_________________________________________________________________\n",
      "Pool1 (MaxPooling2D)         (None, 12, 12, 20)        0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 8, 8, 50)          25050     \n",
      "_________________________________________________________________\n",
      "Pool2 (MaxPooling2D)         (None, 4, 4, 50)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 120)               96120     \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 132,704\n",
      "Trainable params: 132,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model._model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用不同的数据集进行迭代器初始化\n",
    "train_iterator = iterator.make_initializer(train_dataset)\n",
    "val_iterator = iterator.make_initializer(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60032it [00:26, 2262.99it/s]                           \n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Train accuracy: 0.9467, loss: 0.0027\n",
      "Val accuracy: 0.9791, loss: 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60032it [00:26, 2266.18it/s]                           \n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2\n",
      "Train accuracy: 0.9845, loss: 0.0008\n",
      "Val accuracy: 0.9891, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60032it [00:26, 2277.06it/s]                           \n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3\n",
      "Train accuracy: 0.9887, loss: 0.0005\n",
      "Val accuracy: 0.9888, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60032it [00:26, 2269.12it/s]                           \n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4\n",
      "Train accuracy: 0.9921, loss: 0.0004\n",
      "Val accuracy: 0.9890, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60032it [00:26, 2257.29it/s]                           \n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5\n",
      "Train accuracy: 0.9931, loss: 0.0003\n",
      "Val accuracy: 0.9899, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60032it [00:26, 2245.40it/s]                           \n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6\n",
      "Train accuracy: 0.9942, loss: 0.0003\n",
      "Val accuracy: 0.9896, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60032it [00:26, 2278.65it/s]                           \n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7\n",
      "Train accuracy: 0.9954, loss: 0.0002\n",
      "Val accuracy: 0.9903, loss: 0.0004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60032it [00:25, 2311.83it/s]                           \n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8\n",
      "Train accuracy: 0.9962, loss: 0.0002\n",
      "Val accuracy: 0.9924, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60032it [00:26, 2598.09it/s]                           \n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9\n",
      "Train accuracy: 0.9969, loss: 0.0002\n",
      "Val accuracy: 0.9929, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60032it [00:25, 2326.98it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10\n",
      "Train accuracy: 0.9971, loss: 0.0001\n",
      "Val accuracy: 0.9926, loss: 0.0004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = 0, 0\n",
    "        val_loss, val_acc = 0, 0\n",
    "        \n",
    "        # 开始训练\n",
    "        sess.run(train_iterator)\n",
    "        try:\n",
    "            with tqdm(total=60000) as pbar:\n",
    "                while True:\n",
    "                    _, acc, loss = sess.run([model.optimizer, model.accuracy, model.loss])\n",
    "                    train_loss += loss\n",
    "                    train_acc += acc\n",
    "                    pbar.update(batch_size)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        # 开始验证\n",
    "        sess.run(val_iterator)\n",
    "        try:\n",
    "            while True:\n",
    "                acc, loss = sess.run([model.accuracy, model.loss])\n",
    "                val_loss += loss\n",
    "                val_acc += acc\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print(\"\\nEpoch: {}\".format(epoch + 1))\n",
    "        print(\"Train accuracy: {:.4f}, loss: {:.4f}\".format(train_acc / 60000, train_loss / 60000))\n",
    "        print(\"Val accuracy: {:.4f}, loss: {:.4f}\\n\".format(val_acc / 10000, val_loss / 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedable迭代器\n",
    "它提供的功能与可重新初始化迭代器的相同，但在迭代器之间切换时不需要从数据集的开头初始化迭代器。例如，以上面的同一训练和验证数据集为例，您可以使用 tf.data.Iterator.from_string_handle 定义一个可让您在两个数据集之间切换的可馈送迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class Model:\n",
    "    def __init__(self, data_x, data_y):\n",
    "        self.n_classes = 10\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self._create_architecture(self.data_x, self.data_y)\n",
    "    \n",
    "    def _create_architecture(self, x, y):\n",
    "        y_hot = tf.one_hot(y, self.n_classes)\n",
    "        with tf.name_scope(\"Logits\"):\n",
    "            self.logits = self._create_model(x)\n",
    "        predictions = tf.argmax(self.logits, 1, output_type=tf.int32)\n",
    "        with tf.name_scope(\"Loss\"):\n",
    "            self.loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=y_hot, logits=self.logits))\n",
    "        with tf.name_scope(\"Train\"):\n",
    "            self.optimizer = tf.train.AdamOptimizer().minimize(self.loss)\n",
    "        with tf.name_scope(\"Accuracy\"):\n",
    "            self.accuracy = tf.reduce_sum(tf.cast(tf.equal(predictions, y), tf.float32))\n",
    "            \n",
    "    def _create_model(self, x):\n",
    "        input_data = tf.keras.layers.Input(shape=[28, 28, 1], tensor=x, name=\"Input\")\n",
    "        net = tf.keras.layers.Conv2D(kernel_size=(5, 5), filters=20, activation='relu', name=\"Conv1\")(input_data)\n",
    "        net = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, name=\"Pool1\")(net)\n",
    "        net = tf.keras.layers.Conv2D(kernel_size=(5, 5), filters=50, activation='relu', name=\"Conv2\")(net)\n",
    "        net = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, name=\"Pool2\")(net)\n",
    "        net = tf.keras.layers.Flatten(name=\"Flatten\")(net)\n",
    "        net = tf.keras.layers.Dense(120, activation='relu', name=\"Dense1\")(net)\n",
    "        net = tf.keras.layers.Dense(84, activation='relu', name=\"Dense2\")(net)\n",
    "        net = tf.keras.layers.Dense(self.n_classes, activation='linear', name=\"Logits\")(net)\n",
    "        return net\n",
    "    def _model_summary(self):\n",
    "        inputs = tf.keras.layers.Input(shape=[28, 28, 1], name=\"Input\")\n",
    "        outputs = self._create_model(inputs)\n",
    "        model_tmp = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "        model_tmp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备feedable迭代器\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./train_tfrecords/train.tfrecord-045', './train_tfrecords/train.tfrecord-002', './train_tfrecords/train.tfrecord-033']\n",
      "['./test_tfrecords/test.tfrecord-003', './test_tfrecords/test.tfrecord-001', './test_tfrecords/test.tfrecord-002']\n"
     ]
    }
   ],
   "source": [
    "## 准备tfrecord文件名\n",
    "train_filenames = [os.path.join(\"./train_tfrecords/\", i) for i in os.listdir(\"./train_tfrecords/\")]\n",
    "val_filenames = [os.path.join(\"./test_tfrecords/\", i) for i in os.listdir(\"./test_tfrecords/\")]\n",
    "print(train_filenames[:3])\n",
    "print(val_filenames[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 准备解析函数\n",
    "def _parse_func(record):\n",
    "    keys_to_features = {\"img_raw\": tf.FixedLenFeature((), tf.string, default_value=\"\"), \"label\": tf.FixedLenFeature((), tf.int64, default_value=tf.zeros([], tf.int64))}\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "    images = tf.decode_raw(parsed[\"img_raw\"], tf.uint8)\n",
    "    images = tf.reshape(images, [28, 28, 1])\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    images = tf.divide(images, 255.)\n",
    "    labels = tf.cast(parsed[\"label\"], tf.int32)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置超参数\n",
    "epochs = 5\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 分别准备训练和验证数据集\n",
    "train_ds = tf.data.TFRecordDataset(train_filenames)\n",
    "train_ds = train_ds.map(_parse_func)\n",
    "train_ds = train_ds.shuffle(60000).batch(batch_size)\n",
    "\n",
    "val_ds = tf.data.TFRecordDataset(val_filenames)\n",
    "val_ds = val_ds.map(_parse_func)\n",
    "val_ds = val_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tf.float32, tf.int32)\n",
      "(TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(1)]), TensorShape([Dimension(None)]))\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.output_types)\n",
    "print(train_ds.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 可馈送迭代器为每个迭代器赋一个独一无二的字符串句柄\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle, train_ds.output_types, train_ds.output_shapes)\n",
    "data_x, data_y = iterator.get_next()\n",
    "model = Model(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 24, 24, 20)        520       \n",
      "_________________________________________________________________\n",
      "Pool1 (MaxPooling2D)         (None, 12, 12, 20)        0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 8, 8, 50)          25050     \n",
      "_________________________________________________________________\n",
      "Pool2 (MaxPooling2D)         (None, 4, 4, 50)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 120)               96120     \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "Logits (Dense)               (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 132,704\n",
      "Trainable params: 132,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model._model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 为训练集和验证集创建可重新初始化迭代器；如果有测试集，还可以为测试集创建one-shot迭代器\n",
    "train_val_iterator = tf.data.Iterator.from_structure(train_ds.output_types, train_ds.output_shapes)\n",
    "train_iterator = train_val_iterator.make_initializer(train_ds)\n",
    "val_iterator = train_val_iterator.make_initializer(val_ds)\n",
    "\n",
    "# test_iterator = test_ds.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:28<00:00, 2107.65it/s]\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Training accuracy: 0.9347, loss: 0.0021\n",
      "Val accuracy: 0.9823, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:25<00:00, 2342.88it/s]\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2\n",
      "Training accuracy: 0.9824, loss: 0.0006\n",
      "Val accuracy: 0.9856, loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:25<00:00, 2339.32it/s]\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3\n",
      "Training accuracy: 0.9870, loss: 0.0004\n",
      "Val accuracy: 0.9860, loss: 0.0004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:25<00:00, 2312.93it/s]\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4\n",
      "Training accuracy: 0.9894, loss: 0.0003\n",
      "Val accuracy: 0.9908, loss: 0.0003\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:27<00:00, 2214.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5\n",
      "Training accuracy: 0.9921, loss: 0.0002\n",
      "Val accuracy: 0.9904, loss: 0.0003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 创建会话\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 创建句柄\n",
    "    train_val_string = sess.run(train_val_iterator.string_handle())\n",
    "    # test_string = sess.run(test_iterator.string_handle())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = 0, 0\n",
    "        val_loss, val_acc = 0, 0\n",
    "        \n",
    "        # 开始训练\n",
    "        sess.run(train_iterator)\n",
    "        try:\n",
    "            with tqdm(total=60000) as pbar:\n",
    "                while True:\n",
    "                    _, loss, acc = sess.run([model.optimizer, model.loss, model.accuracy], feed_dict={handle: train_val_string})\n",
    "                    train_loss += loss\n",
    "                    train_acc += acc\n",
    "                    pbar.update(batch_size)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        # 开始验证\n",
    "        sess.run(val_iterator)\n",
    "        try:\n",
    "            while True:\n",
    "                loss, acc = sess.run([model.loss, model.accuracy], feed_dict={handle: train_val_string})\n",
    "                val_loss += loss\n",
    "                val_acc += acc\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print(\"\\nEpoch: {}\".format(epoch + 1))\n",
    "        print(\"Training accuracy: {:.4f}, loss: {:.4f}\".format(train_acc / 60000, train_loss / 60000))\n",
    "        print(\"Val accuracy: {:.4f}, loss: {:.4f}\\n\".format(val_acc / 10000, val_loss / 10000))\n",
    "        \n",
    "#     test_loss, test_acc = 0, 0\n",
    "#     try:\n",
    "#         while True:\n",
    "#             loss, acc = sess.run([model.loss, model.accuracy], feed_dict={handle: test_string})\n",
    "#             test_loss += loss\n",
    "#             test_acc += acc\n",
    "#     except tf.errors.OutOfRangeError:\n",
    "#         pass\n",
    "# print(\"\\nTest accuracy: {:.4f}, loss: {:.4f}\".format(test_acc / len(y_test), test_loss / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
