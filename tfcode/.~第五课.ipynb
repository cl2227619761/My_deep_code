{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积神经网络\n",
    "# ConvNet with MNIST\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_relu(inputs, filters, k_size, strides, padding, scope_name):\n",
    "    \"\"\"计算conv+relu的结果\"\"\"\n",
    "    with tf.variable_scope(scope_name, reuse=tf.AUTO_REUSE) as scope:\n",
    "        in_channels = inputs.shape[-1]\n",
    "        kernel = tf.get_variable(name='kernel', \n",
    "                                shape=[k_size, k_size, in_channels, filters],\n",
    "                                initializer=tf.truncated_normal_initializer())\n",
    "        biases = tf.get_variable(name='biases',\n",
    "                                shape=[filters],\n",
    "                                initializer=tf.random_normal_initializer())\n",
    "        conv = tf.nn.conv2d(inputs, kernel, strides=[1, strides, strides, 1], padding=padding)\n",
    "    return tf.nn.relu(conv + biases, name=scope.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function conv2d in module tensorflow.python.ops.gen_nn_ops:\n",
      "\n",
      "conv2d(input, filter, strides, padding, use_cudnn_on_gpu=True, data_format='NHWC', dilations=[1, 1, 1, 1], name=None)\n",
      "    Computes a 2-D convolution given 4-D `input` and `filter` tensors.\n",
      "    \n",
      "    Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
      "    and a filter / kernel tensor of shape\n",
      "    `[filter_height, filter_width, in_channels, out_channels]`, this op\n",
      "    performs the following:\n",
      "    \n",
      "    1. Flattens the filter to a 2-D matrix with shape\n",
      "       `[filter_height * filter_width * in_channels, output_channels]`.\n",
      "    2. Extracts image patches from the input tensor to form a *virtual*\n",
      "       tensor of shape `[batch, out_height, out_width,\n",
      "       filter_height * filter_width * in_channels]`.\n",
      "    3. For each patch, right-multiplies the filter matrix and the image patch\n",
      "       vector.\n",
      "    \n",
      "    In detail, with the default NHWC format,\n",
      "    \n",
      "        output[b, i, j, k] =\n",
      "            sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *\n",
      "                            filter[di, dj, q, k]\n",
      "    \n",
      "    Must have `strides[0] = strides[3] = 1`.  For the most common case of the same\n",
      "    horizontal and vertices strides, `strides = [1, stride, stride, 1]`.\n",
      "    \n",
      "    Args:\n",
      "      input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.\n",
      "        A 4-D tensor. The dimension order is interpreted according to the value\n",
      "        of `data_format`, see below for details.\n",
      "      filter: A `Tensor`. Must have the same type as `input`.\n",
      "        A 4-D tensor of shape\n",
      "        `[filter_height, filter_width, in_channels, out_channels]`\n",
      "      strides: A list of `ints`.\n",
      "        1-D tensor of length 4.  The stride of the sliding window for each\n",
      "        dimension of `input`. The dimension order is determined by the value of\n",
      "        `data_format`, see below for details.\n",
      "      padding: A `string` from: `\"SAME\", \"VALID\"`.\n",
      "        The type of padding algorithm to use.\n",
      "      use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.\n",
      "      data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`. Defaults to `\"NHWC\"`.\n",
      "        Specify the data format of the input and output data. With the\n",
      "        default format \"NHWC\", the data is stored in the order of:\n",
      "            [batch, height, width, channels].\n",
      "        Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "            [batch, channels, height, width].\n",
      "      dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.\n",
      "        1-D tensor of length 4.  The dilation factor for each dimension of\n",
      "        `input`. If set to k > 1, there will be k-1 skipped cells between each\n",
      "        filter element on that dimension. The dimension order is determined by the\n",
      "        value of `data_format`, see above for details. Dilations in the batch and\n",
      "        depth dimensions must be 1.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `input`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool(inputs, k_size, strides, padding='VALID', scope_name='pool'):\n",
    "    '''A method that does max pooling on inputs'''\n",
    "    with tf.variable_scope(scope_name, reuse=tf.AUTO_REUSE) as scope:\n",
    "        pool = tf.nn.max_pool(inputs, \n",
    "                            ksize=[1, k_size, k_size, 1], \n",
    "                            strides=[1, strides, strides, 1],\n",
    "                            padding=padding)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(inputs, out_dim, scope_name='fc'):\n",
    "    with tf.variable_scope(scope_name, reuse=tf.AUTO_REUSE) as scope:\n",
    "        in_dim = inputs.shape[-1]\n",
    "        w = tf.get_variable(name='weights', shape=[in_dim, out_dim], initializer=tf.truncated_normal_initializer())\n",
    "        b = tf.get_variable(name='biases', shape=[out_dim], initializer=tf.constant_initializer(0.0))\n",
    "        out = tf.matmul(inputs, w) + b\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def load_data(filepath, batch_size):\n",
    "        mnist = input_data.read_data_sets(filepath, one_hot=True)\n",
    "        x_train, y_train, x_valid, y_valid, x_test, y_test = mnist.train.images, mnist.train.labels, mnist.validation.images, mnist.validation.labels, mnist.test.images, mnist.test.labels\n",
    "        x_train, x_valid, x_test = x_train.astype('float32') / 255., x_valid.astype('float32') / 255., x_test.astype('float32') / 255.\n",
    "        train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "        train_data = train_data.shuffle(10000)\n",
    "        train_data = train_data.batch(batch_size)\n",
    "        \n",
    "        test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "        test_data = test_data.batch(batch_size)\n",
    "        return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def safe_mkdir(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "class ConvNet(object):\n",
    "    def __init__(self):\n",
    "        self.lr = 0.001\n",
    "        self.batch_size = 20\n",
    "        self.keep_prob = tf.constant(0.75)\n",
    "        self.gstep = tf.Variable(0, dtype=tf.int32, \n",
    "                                trainable=False, name='global_step')\n",
    "        self.n_classes = 10\n",
    "        self.skip_step = 20\n",
    "        self.n_test = 10000\n",
    "        self.training = True\n",
    "\n",
    "    def get_data(self):\n",
    "        with tf.name_scope('data'):\n",
    "            train_data, test_data = utils.get_mnist_dataset(self.batch_size)\n",
    "            iterator = tf.data.Iterator.from_structure(train_data.output_types, \n",
    "                                                   train_data.output_shapes)\n",
    "            img, self.label = iterator.get_next()\n",
    "            self.img = tf.reshape(img, shape=[-1, 28, 28, 1])\n",
    "            # reshape the image to make it work with tf.nn.conv2d\n",
    "\n",
    "            self.train_init = iterator.make_initializer(train_data)  # initializer for train_data\n",
    "            self.test_init = iterator.make_initializer(test_data)    # initializer for train_data\n",
    "\n",
    "    def inference(self):\n",
    "        conv1 = conv_relu(inputs=self.img,\n",
    "                        filters=32,\n",
    "                        k_size=5,\n",
    "                        strides=1,\n",
    "                        padding='SAME',\n",
    "                        scope_name='conv1')\n",
    "        pool1 = maxpool(conv1, 2, 2, 'VALID', 'pool1')\n",
    "        conv2 = conv_relu(inputs=pool1,\n",
    "                        filters=64,\n",
    "                        k_size=5,\n",
    "                        strides=1,\n",
    "                        padding='SAME',\n",
    "                        scope_name='conv2')\n",
    "        pool2 = maxpool(conv2, 2, 2, 'VALID', 'pool2')\n",
    "        feature_dim = pool2.shape[1] * pool2.shape[2] * pool2.shape[3]\n",
    "        pool2 = tf.reshape(pool2, [-1, feature_dim])\n",
    "        fc = fully_connected(pool2, 1024, 'fc')\n",
    "        dropout = tf.nn.dropout(tf.nn.relu(fc), self.keep_prob, name='relu_dropout')\n",
    "        self.logits = fully_connected(dropout, self.n_classes, 'logits')\n",
    "\n",
    "    def loss(self):\n",
    "        '''\n",
    "        define loss function\n",
    "        use softmax cross entropy with logits as the loss function\n",
    "        compute mean cross entropy, softmax is applied internally\n",
    "        '''\n",
    "        # \n",
    "        with tf.name_scope('loss'):\n",
    "            entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.label, logits=self.logits)\n",
    "            self.loss = tf.reduce_mean(entropy, name='loss')\n",
    "    \n",
    "    def optimize(self):\n",
    "        '''\n",
    "        Define training op\n",
    "        using Adam Gradient Descent to minimize cost\n",
    "        '''\n",
    "        self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.loss, \n",
    "                                                global_step=self.gstep)\n",
    "\n",
    "    def summary(self):\n",
    "        '''\n",
    "        Create summaries to write on TensorBoard\n",
    "        '''\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "            tf.summary.scalar('accuracy', self.accuracy)\n",
    "            tf.summary.histogram('histogram_loss', self.loss)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    def eval(self):\n",
    "        '''\n",
    "        Count the number of right predictions in a batch\n",
    "        '''\n",
    "        with tf.name_scope('predict'):\n",
    "            preds = tf.nn.softmax(self.logits)\n",
    "            correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(self.label, 1))\n",
    "            self.accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "    def build(self):\n",
    "        '''\n",
    "        Build the computation graph\n",
    "        '''\n",
    "        self.get_data()\n",
    "        self.inference()\n",
    "        self.loss()\n",
    "        self.optimize()\n",
    "        self.eval()\n",
    "        self.summary()\n",
    "\n",
    "    def train_one_epoch(self, sess, saver, init, writer, epoch, step):\n",
    "        start_time = time.time()\n",
    "        sess.run(init) \n",
    "        self.training = True\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l, summaries = sess.run([self.opt, self.loss, self.summary_op])\n",
    "                writer.add_summary(summaries, global_step=step)\n",
    "                if (step + 1) % self.skip_step == 0:\n",
    "                    print('Loss at step {0}: {1}'.format(step, l))\n",
    "                step += 1\n",
    "                total_loss += l\n",
    "                n_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        saver.save(sess, 'checkpoints/convnet_mnist/mnist-convnet', step)\n",
    "        print('Average loss at epoch {0}: {1}'.format(epoch, total_loss/n_batches))\n",
    "        print('Took: {0} seconds'.format(time.time() - start_time))\n",
    "        return step\n",
    "\n",
    "    def eval_once(self, sess, init, writer, epoch, step):\n",
    "        start_time = time.time()\n",
    "        sess.run(init)\n",
    "        self.training = False\n",
    "        total_correct_preds = 0\n",
    "        try:\n",
    "            while True:\n",
    "                accuracy_batch, summaries = sess.run([self.accuracy, self.summary_op])\n",
    "                writer.add_summary(summaries, global_step=step)\n",
    "                total_correct_preds += accuracy_batch\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "        print('Accuracy at epoch {0}: {1} '.format(epoch, total_correct_preds/self.n_test))\n",
    "        print('Took: {0} seconds'.format(time.time() - start_time))\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "        '''\n",
    "        The train function alternates between training one epoch and evaluating\n",
    "        '''\n",
    "        utils.safe_mkdir('checkpoints')\n",
    "        utils.safe_mkdir('checkpoints/convnet_mnist')\n",
    "        writer = tf.summary.FileWriter('./graphs/convnet', tf.get_default_graph())\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver = tf.train.Saver()\n",
    "            ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/convnet_mnist/checkpoint'))\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            step = self.gstep.eval()\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                step = self.train_one_epoch(sess, saver, self.train_init, writer, epoch, step)\n",
    "                self.eval_once(sess, self.test_init, writer, epoch, step)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 19: 30401.671875\n",
      "Loss at step 39: 15979.474609375\n",
      "Loss at step 59: 15600.5498046875\n",
      "Loss at step 79: 6402.73828125\n",
      "Loss at step 99: 5084.900390625\n",
      "Loss at step 119: 10184.7841796875\n",
      "Loss at step 139: 2844.965087890625\n",
      "Loss at step 159: 4015.928466796875\n",
      "Loss at step 179: 4127.40380859375\n",
      "Loss at step 199: 389.55987548828125\n",
      "Loss at step 219: 2648.35302734375\n",
      "Loss at step 239: 6330.11083984375\n",
      "Loss at step 259: 6031.20263671875\n",
      "Loss at step 279: 1450.073974609375\n",
      "Loss at step 299: 384.7294921875\n",
      "Loss at step 319: 2009.578857421875\n",
      "Loss at step 339: 624.6025390625\n",
      "Loss at step 359: 2920.165283203125\n",
      "Loss at step 379: 3692.25537109375\n",
      "Loss at step 399: 4358.75244140625\n",
      "Loss at step 419: 2375.29443359375\n",
      "Loss at step 439: 1594.308349609375\n",
      "Loss at step 459: 235.6687469482422\n",
      "Loss at step 479: 0.0\n",
      "Loss at step 499: 6040.89501953125\n",
      "Loss at step 519: 0.0\n",
      "Loss at step 539: 1393.523681640625\n",
      "Loss at step 559: 2842.12451171875\n",
      "Loss at step 579: 0.0\n",
      "Loss at step 599: 157.84521484375\n",
      "Loss at step 619: 2022.3695068359375\n",
      "Loss at step 639: 1251.214599609375\n",
      "Loss at step 659: 541.9686279296875\n",
      "Loss at step 679: 2554.404296875\n",
      "Loss at step 699: 1867.87109375\n",
      "Loss at step 719: 2375.4833984375\n",
      "Loss at step 739: 1510.8804931640625\n",
      "Loss at step 759: 3704.04150390625\n",
      "Loss at step 779: 696.2278442382812\n",
      "Loss at step 799: 1228.948486328125\n",
      "Loss at step 819: 1616.237548828125\n",
      "Loss at step 839: 1438.858154296875\n",
      "Loss at step 859: 1676.585205078125\n",
      "Loss at step 879: 481.60247802734375\n",
      "Loss at step 899: 591.42236328125\n",
      "Loss at step 919: 694.8642578125\n",
      "Loss at step 939: 1492.650634765625\n",
      "Loss at step 959: 595.955078125\n",
      "Loss at step 979: 878.9873046875\n",
      "Loss at step 999: 450.38751220703125\n",
      "Loss at step 1019: 983.2960815429688\n",
      "Loss at step 1039: 1554.4984130859375\n",
      "Loss at step 1059: 65.93867492675781\n",
      "Loss at step 1079: 0.0\n",
      "Loss at step 1099: 1204.669677734375\n",
      "Loss at step 1119: 136.56484985351562\n",
      "Loss at step 1139: 2927.278564453125\n",
      "Loss at step 1159: 341.01019287109375\n",
      "Loss at step 1179: 324.9126892089844\n",
      "Loss at step 1199: 741.5712280273438\n",
      "Loss at step 1219: 974.2584228515625\n",
      "Loss at step 1239: 561.9010009765625\n",
      "Loss at step 1259: 1456.1690673828125\n",
      "Loss at step 1279: 1951.10546875\n",
      "Loss at step 1299: 2117.20703125\n",
      "Loss at step 1319: 184.0803680419922\n",
      "Loss at step 1339: 1320.3472900390625\n",
      "Loss at step 1359: 402.0677185058594\n",
      "Loss at step 1379: 122.0845718383789\n",
      "Loss at step 1399: 1281.9827880859375\n",
      "Loss at step 1419: 190.58511352539062\n",
      "Loss at step 1439: 1407.337890625\n",
      "Loss at step 1459: 0.0\n",
      "Loss at step 1479: 467.1685485839844\n",
      "Loss at step 1499: 0.0\n",
      "Loss at step 1519: 1169.501708984375\n",
      "Loss at step 1539: 1133.8170166015625\n",
      "Loss at step 1559: 896.4769287109375\n",
      "Loss at step 1579: 834.3431396484375\n",
      "Loss at step 1599: 260.2265625\n",
      "Loss at step 1619: 1330.529052734375\n",
      "Loss at step 1639: 1960.9566650390625\n",
      "Loss at step 1659: 755.1383666992188\n",
      "Loss at step 1679: 248.36001586914062\n",
      "Loss at step 1699: 556.8030395507812\n",
      "Loss at step 1719: 456.68218994140625\n",
      "Loss at step 1739: 324.1702880859375\n",
      "Loss at step 1759: 209.68124389648438\n",
      "Loss at step 1779: 293.71295166015625\n",
      "Loss at step 1799: 1278.435791015625\n",
      "Loss at step 1819: 1142.697265625\n",
      "Loss at step 1839: 678.8659057617188\n",
      "Loss at step 1859: 0.0\n",
      "Loss at step 1879: 59.30656814575195\n",
      "Loss at step 1899: 192.57333374023438\n",
      "Loss at step 1919: 461.8558654785156\n",
      "Loss at step 1939: 242.04818725585938\n",
      "Loss at step 1959: 0.0\n",
      "Loss at step 1979: 32.441307067871094\n",
      "Loss at step 1999: 99.257568359375\n",
      "Loss at step 2019: 393.3370666503906\n",
      "Loss at step 2039: 297.83026123046875\n",
      "Loss at step 2059: 149.70498657226562\n",
      "Loss at step 2079: 729.822509765625\n",
      "Loss at step 2099: 101.9498062133789\n",
      "Loss at step 2119: 127.3633804321289\n",
      "Loss at step 2139: 46.127784729003906\n",
      "Loss at step 2159: 484.4169921875\n",
      "Loss at step 2179: 0.0\n",
      "Loss at step 2199: 15.107324600219727\n",
      "Loss at step 2219: 156.238037109375\n",
      "Loss at step 2239: 0.0\n",
      "Loss at step 2259: 0.0\n",
      "Loss at step 2279: 119.0975570678711\n",
      "Loss at step 2299: 72.77119445800781\n",
      "Loss at step 2319: 0.0\n",
      "Loss at step 2339: 0.0\n",
      "Loss at step 2359: 752.3162841796875\n",
      "Loss at step 2379: 253.21304321289062\n",
      "Loss at step 2399: 284.9715881347656\n",
      "Loss at step 2419: 1819.369873046875\n",
      "Loss at step 2439: 0.0\n",
      "Loss at step 2459: 20.058618545532227\n",
      "Loss at step 2479: 264.1656799316406\n",
      "Loss at step 2499: 32.47771072387695\n",
      "Loss at step 2519: 50.62150955200195\n",
      "Loss at step 2539: 57.986671447753906\n",
      "Loss at step 2559: 43.386436462402344\n",
      "Loss at step 2579: 0.0\n",
      "Loss at step 2599: 463.6845703125\n",
      "Loss at step 2619: 1.493615746498108\n",
      "Loss at step 2639: 1150.364501953125\n",
      "Loss at step 2659: 587.8917236328125\n",
      "Loss at step 2679: 149.04153442382812\n",
      "Loss at step 2699: 0.0\n",
      "Loss at step 2719: 221.017822265625\n",
      "Loss at step 2739: 75.2584457397461\n",
      "Average loss at epoch 0: 1511.0103626284533\n",
      "Took: 100.80095791816711 seconds\n",
      "Accuracy at epoch 0: 0.939 \n",
      "Took: 4.870381116867065 seconds\n",
      "Loss at step 2759: 0.0\n",
      "Loss at step 2779: 0.0\n",
      "Loss at step 2799: 232.667724609375\n",
      "Loss at step 2819: 0.0\n",
      "Loss at step 2839: 355.80572509765625\n",
      "Loss at step 2859: 620.2288208007812\n",
      "Loss at step 2879: 8.708765029907227\n",
      "Loss at step 2899: 0.0\n",
      "Loss at step 2919: 552.3857421875\n",
      "Loss at step 2939: 135.984130859375\n",
      "Loss at step 2959: 1042.755126953125\n",
      "Loss at step 2979: 68.2681655883789\n",
      "Loss at step 2999: 727.4514770507812\n",
      "Loss at step 3019: 27.720775604248047\n",
      "Loss at step 3039: 317.0845642089844\n",
      "Loss at step 3059: 0.0\n",
      "Loss at step 3079: 67.0489273071289\n",
      "Loss at step 3099: 0.0\n",
      "Loss at step 3119: 89.3658676147461\n",
      "Loss at step 3139: 358.6566467285156\n",
      "Loss at step 3159: 83.3197250366211\n",
      "Loss at step 3179: 0.0\n",
      "Loss at step 3199: 0.0\n",
      "Loss at step 3219: 127.87019348144531\n",
      "Loss at step 3239: 0.0\n",
      "Loss at step 3259: 0.0\n",
      "Loss at step 3279: 43.42509841918945\n",
      "Loss at step 3299: 1095.556640625\n",
      "Loss at step 3319: 11.228442192077637\n",
      "Loss at step 3339: 326.0511779785156\n",
      "Loss at step 3359: 708.895263671875\n",
      "Loss at step 3379: 0.0\n",
      "Loss at step 3399: 14.673266410827637\n",
      "Loss at step 3419: 36.557769775390625\n",
      "Loss at step 3439: 103.04219055175781\n",
      "Loss at step 3459: 604.4757690429688\n",
      "Loss at step 3479: 52.016845703125\n",
      "Loss at step 3499: 63.196205139160156\n",
      "Loss at step 3519: 0.0\n",
      "Loss at step 3539: 0.0\n",
      "Loss at step 3559: 51.68852615356445\n",
      "Loss at step 3579: 0.0\n",
      "Loss at step 3599: 92.34814453125\n",
      "Loss at step 3619: 21.518896102905273\n",
      "Loss at step 3639: 97.4905776977539\n",
      "Loss at step 3659: 0.0\n",
      "Loss at step 3679: 49.295066833496094\n",
      "Loss at step 3699: 0.0\n",
      "Loss at step 3719: 12.639501571655273\n",
      "Loss at step 3739: 614.630615234375\n",
      "Loss at step 3759: 261.25018310546875\n",
      "Loss at step 3779: 0.0\n",
      "Loss at step 3799: 223.1966552734375\n",
      "Loss at step 3819: 295.9051208496094\n",
      "Loss at step 3839: 628.9876708984375\n",
      "Loss at step 3859: 237.4599609375\n",
      "Loss at step 3879: 689.6934814453125\n",
      "Loss at step 3899: 14.528185844421387\n",
      "Loss at step 3919: 0.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = ConvNet()\n",
    "    model.build()\n",
    "    model.train(n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
